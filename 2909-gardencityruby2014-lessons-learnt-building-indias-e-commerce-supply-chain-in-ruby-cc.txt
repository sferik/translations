Garden City Ruby 2014 - Yogi Kulkarni - Lessons Learnt Building India's E-Commerce Supply Chain in Ruby

This talk is about a specific project that we did at Flipkart

so just to give people, foreigners here, a bit of context of Flipkart 

it's sort of like the Amazon of India

and they are the largest e-commerce store in India

we, so yeah, let me keep the numbers for later

so, in 2011 around about in December

there was the, we had a kind of a moment where 

we realized that our supply chain was not going to be able to scale

we were having very, very serious problems

with actually having things, with things, 

actually building new features

it was going very slow

the number of requests hitting our website

were just going through the roof and

and we were not able to keep up

so at that point there was a

so let me just actually talk about what the system looked like

so, this was Version 2 of the supply chain at Flipkart

Version 1 which was kind of written in 2007

was written by our founder, Sachin and Binny themselves in PHP

so this was Version 2, which was written in about 2010

it was Open Source ERP system called Opentaps

which we had extended extensively

it was basically a single monolithic application

it had all these modules for the management, warehousing, so on and so forth

and they all came out of a single JVM

connected to a single database

and that was just horrible

right

the problem was that

each module as we were extending it

the developers didn't actually bother

to kind of think about

should we be accessing this data

this table, should we be crediting it or not

they would just go and make joins across tables

just to solve the problem, get the feature out

right

you're probably familiar with that

so horrible coupling

and we spent about a month trying to see if we can

call up (?? 00:02:22,40)

each piece from the system

and kind of start picking out services

and we couldn't do it

it was just impossible

so, at that point we took a hard, hard decision that

you know, let's actually rewrite

and this was something which was completely against

my past works OR Flipkart works (?? 00:02:35,74)

philosophy of, you know, let's re-factor incrementally

and go slowly and let's have the system running and then

kind of migrate, but

we took the score

and in two-thousand-and, I think it was 2011, in December

we started the project

where, so this was

sort of a 

bed OR bet (?? 00:02:54,30)

the company project for Flipkart

it was so critical at that point that

Sachin, he was the founder, actually came and sat with the team

so we basically 

called up (?? 00:03:02,75)

a team of initially ten people and then

that increased to about thirty developers

and he moved us, moved that team out

to a separate office

which was basically a house

in Banglore, which was the place where

Flipkart was born

and that was, got turned into a 

skunk (?? 00:03:17,65)

works start-up project within Flipkart

where this team worked

and complete isolation

no interviews, no meetings, nothing

this team was only here to build out this system in seven months

because the next milestone was the Diwali

so the Diwali is the time when

we do the most sales in the year

and that was in October of 2012

so we had about seven months to replace

an entire supply chain system

with a new system built from grounds up

get it in production, make sure it's working

and it's scaling right

so get to, probably do it by August

and give ourselves time till August to kind of do that

so yeah, we start up on this project and

the idea was to 

break up each of these modules into

services and I think Chad's talk

really set up the context beautifully for the start

because a lot of the ideas and processes

that he mentioned is stuff that 

we tried to kind of

work on and kind of implement in the system

so, some of the things he wanted to do was

I think it was nice because

it's all small pieces loosely joined

which I came across around that time

I think that beautifully summarizes what

we want to get to

right

each service doing one small thing

so you break down

the warehouse module into a separate service

order management into a separate service

accounting and so on and so forth

we didn't want to go down

micro-services architecture way

I'd worked with Fred George earlier and

I'd gone down, I'd seen of the down sides

of it and I didn't actually have a clear idea of

how to work around those downsides at that point in time

so I was kind of wary about micro-services at that point

and I would love to actually hear other peoples' thoughts

on how that's working out

but anyway, so we all took on our separate services

each doing one thing and doing one thing well

and each service would have its own database

and nobody could access it except the servers

right

you could just access it through an HTTP JSON API

and you will never touch my data

right

my private parts are private

so this is what we ended up with

probably not going to read the thing so I'm gonna read it out to you

so we end up with about twenty-five services

this is a sub-set of the services we actually built

you have all the management service

then the fulfillment orchestration service

which talks to warehousing service

and fulfillment, which in turn talks to supplier

and the whole logistics subsystems 

and you have accounting services

document services

and then you have a bunch of

infrastructure services including this piece at the bottom

which was a messaging system that we ended up building

called Resbus, which I talk a little bit about

which kind of addressed the problem of cross-service transaction integrity

so in this picture the Ruby services were basic- so

each service, for example, the order management service

the blue pieces were written in Padrino or Sinatra

[mumbling]

so these are in Padrino and

00:06:38.12

and added

OR

and also

OR

the add-on

00:06:37.61

JRuby when we went live

we eventually migrated those to MRI

but, and I'm going to be clear about why

so these were the Padrino services

and then the UI pieces where required were written in Ruby on Rails

running on MRI

we also had some infrastructure services running on Ruby

for example the single sign-on service was

and used (?? 00:06:57,7) CAS and used RubyCAS

we built our rule-based access system again in Ruby

and a bunch of other pieces

right

so essentially we went from monolithic single system

to twenty-five services

right

and this was a massive change

and this, so each, there were total about seven teams

which worked on this project

owning one or two services

each team had between four and six developers

yeah, so that's to just set the context

about where we were

so, when we started the project in two thousand and, early

2011, we were doing about

the old system was doing, the system was doing about

20,000 orders a day

30,000 shipments a day

roughly around that order

and this new system has now survived 

two Diwali workloads

which includes the latest Diwali which was in 2013

we did, I think 100,000 orders and 150,000 shipments

and it's working pretty well

so, at the time when we were making this decision

we were kind of selecting the technology stack

and we, the big question was, you know, what tech stack to use

so Flipkart traditionally had a lot

so we, Opentabs given the Java stack

so most developers were very, very comfortable with Java

so the thought of actually introducing a new language

a new ecosystem

was, people were kind of wary about that

also there were concerns about performance

but, I knew from my experience in the past that

performance is not a language issue

it's an architecture design issue fundamentally

right

and there  are differences in technologies and languages

and I talk a little bit more about that in detail

but performance I'm not too worried about

so why Ruby then?

so there's a, the obvious reason is

speed of development

right

we had a short, a very, very tight deadline

to detail the

?? (00:09:13,5)

system in seven months

we wanted to move fast

right 

so that's obviously one benefit

the other reason was

I think this idea of small pieces loosely joined

is really powerful

small code pieces are inherently easier to debug

right

like even if you have the best tools and you have a large Jar system

it's hard to work even if things are great for filers

great modeling tools

it's still hard when you are dealing

with 100,000 line code base

you, it's just far more complex than dealing with

something that is maybe 10,000 lines

or maybe 5,000 lines of code right

and that code compression that Ruby allows

is actually really powerful

also I think in the Ruby world

Ruby's secret weapon is not Rails

I think to me, Ruby's secret weapon is activerecord

especially for business applications

there's, I just love it as a new item tool

and it has its problems

especially in the enterprise space when

you are dealing with fairly complex logic

a lot of cases where

so because it lacks what's called an identity map

you can have situations where if you're not traversing from

parent to object, to a child object, and back

to the parent object, you end up with two references to the

two instances of the parent object

right

and that's kind of bad

tools like Hibernate in the Java world actually solve this beautifully

so yeah, so it has its glitches

but still, as a tool to write business applications

I think there's, it's fairly amazing

so we want to use the power of activerecord

we want to have small systems

which is why we built our services

back-end services which were the HTTP JSON ones

only in Sinatra

so Padrino was just a pin wrapped around it

so it's Sinatra talking to its own database

OK, so I'm gonna kind of try and focus a lot more on the lessons learned

so I'm kind of going to be jumping topics a bit 

and it might be a bit of discontinuity so

you'll excuse that

but I want to kind of get the real key insights that we had on the project out

than worry about a kind of a consistent flow

so JRuby

right

let me start it off good

so JRuby is incredible

it's an amazing piece of technology, great community

you get the power of the JVM which is just amazing

and specifically within the JVM what you want is

it's garbage collector

and the just-in-time compilation

very cohesive (?? 00:11:46,7)

those two are just amazing

I'll share some numbers about how those two things actually make a difference

but that's a good part of JRuby

right

amazing ecosystem

you get all the tools that are in the Jar would just work

not just work, but they work OK with, in JRuby context

but still you get a lot of tools like this that can be used, et cetera

the bad

so what's bad about JRuby?

one thing that gets talked about a lot is its slow start-up time

and it is a massive, massive issue

typically, when you're kind of coding

particularly when you're testing, you want

to have a very quick cycle of going from test to code to test

and back and forth

but that's hard to do with JRuby

and there are other things you can do

you can use things like ?? (00:12:43,4)

is almost like using Nailgun, for example, or Spork

(00:12:46,2) ?? (00:12:47,8)

and then connect to it and run tests against it

so all that is fine but

it's still very sluggish to work with

right

so you end up having to do a

to kind of jump through hoops to work good on that problem

for example

we ended up writing

so all our development was in CRuby

so tests run very fast, specs run fast, scripts run fast

but you deploy to JRuby

but even then, even for CI

and for deployment, you end up isolating

kind of scripts which were launched in CRuby

but they were in turn just launched JRuby just for the pieces which actually required JRuby

so you had to kind of do a bunch of these things

just kind of, not great

so but all this you could kind of live with, right

there's one thing about JRuby which surprisingly isn't talked about so much

which I think is fundamentally a deal breaker

and that's its test suite

it's actually 

it's not actually a JRuby problem

I just think the Ruby world is just not ready to work on truly multi-threaded Ruby interpreter

right, which is without a global interpreter lock

and this manifested in horrible, horrible bugs for us

so when you start working at scale

you know you're getting tons of requests

in the system

so these problems typically don't manifest when you're running a small service

and you know JRuby works fine for that

all good

but you will run into cases where

some library was not written with thread safety in mind

and that will just kill you

and it is virtually impossible to debug

so the beefiest problems with Padrino

where the actual app wouldn't get initialized

and it was just horrible bring it out

and the problem turned out to be something

in HTTP router, which is a Gem used for actual route of creation

and there's no fix for that

it's been over a year and a half

and it's still not been fixed

we actually put in a patch to Padrino to actually work 

so we cleared the rack filter

which kind of hand-holds the initializing process

and initializes each BM correctly

it was just horrible, horrible, horrible code

so that's one

HTR is one example

there was sadly we were activerecord right

we were on 3.1.x

so activerecord has got concurrency, has got concept issues 

and they don't show up again on, in normal situations

they show up at scale, at high load

the connection pool is actually not thread safe

so we had situations where the same connection was being returned to two different 

to two different threads and

they would end up just messing up the data base

or the transaction

so essentially what would happen was

the transaction would commit

the, but, the service would say OK

200, all OK, committed

and you would go back and see there's no data in the data base

because the transaction never committed

the connection was basically rolled back at some point

and nobody knew anything about it

no framework user at activerecord didn't know anything about it

Padrino didn't know anything about it

so this was horrible and we couldn't figure out

we tried patching, we've actually patched activerecord quite a bit

but we couldn't get that to work

so we actually went live with the JRuby

in September of 2012

and I think in three months after kind of struggling with these issues

we kind of threw a call to move back to CRuby

and that was

a kind of sad moment because I really, really loved JRuby

and the great joys of people using it in production

not too many, but yes there are

and its potential is there but the problem is the libraries

and developers are still not in that Java mindset

surprisingly Java does this very well

they're kind of constantly thinking about thread safety

but the Ruby world is still not part of that

they'll probably get there soon

yeah

so we moved to CRuby and

that sorted out a lot of performance issues

rather thread safety issues

I'll talk about the performance parts actually

I'm gonna comparison

yeah also besides performance  I'm guessing you're saying

but that wasn't too much of an issue

OK so I mentioned this briefly

I'll just touch on it

so what's a problem here

right

so when you have a bunch of services like this

right

when you have a single monollithic application

you can start at, you have a request which comes and kind of

touches multiple databases or the management warehouse

and you can run that, all those database changes in a single transacation

right

it commits or doesn't commit

everyone's happy

all beautiful

the moment you go to something like this

that doesn't work right

supposing how a transaction which say

called create order

which kind of enters the create order request which comes

through the order management system

it basically makes the call to approve that order

the fulfillment of strata

and the, as part of the fulfillment orchestrated basically tells the warehouse service

that they're all, they don't have the stuff in stock

so I'm gonna actually order it for you

so he tells the procurement service to go on order this item

but he also has to tell warehouse that OK

expect this item I'm ordering it for you

expect it, right

now those two things which is

placing the order with the supplier and

expect the order

has to happen as kind of automatically

right

has to happen automatically along with the commit of the approval

ok, it got approave and I've told this guy to procure it

and I've told warehouse to expect it

I have these two things that happen

at one time

now this is a really, really hard problem to solve

and it's

so, the way you solve that typically

is to, in the enterprise world

is to use the stored transaction call data

so, most of the (00:18:46,7) ?? service

for example do that

they actually have, they kind of implement the two face commit

and you can actually have a database

two databases

take part in a single transaction or two phases, right

that's one way to do it

the problem with that is that

completely breaks service isolation 

like now I've got a distributed transaction coordinator

which is going to be sitting ?? (00:19:09,1)

and coordinating transactions between this database and

this guy

and if you remember the original principle right

I don't want to expose my database

right

I want to expose my service

so it kind of breaks service and translation very badly

and that's the least of the problems, right

the bigger problem is that it degrades 

it's basically a way to ensure system doesn't scale

because, sorry

when you have a transaction spanning multiple systems

it essentially is what's happening is happening under the hood

for each database

the resource packages requiring some locks on some rows in the table

and those are now held for a much longer time

because you're going to go through two passes through it

right

so essentially you end up holding locks

on database rows for much longer

which increases contention and reduces book problems

right

so then how do you solve this problem

right

so the way you solve it 

so then the other option is to actually go in for something like

use messaging

you actually send messages to other services

and the push to the message cue

and the right database has to happen as one transaction

right

so that's another option

but again you need a distributed transaction coordinator

to kind of manage the two face commit coming between

the message cue and the database

so what we end up doing is views

are you serious? ten minutes? all right

so yeah

so we end up creating a service called Resbus which kind of

it actually does local transactions

and asyncronous relayer of messages

to actually call upon and I can talk offline about that

in more detail if anybody's interested

so what we learned there though was

this, the power of HTTP as integration glue

was just understated right

we end up creating, using, messaging systems

and use databases and

why do you need that

why can't messaging be exposed as a HTTP inquiry?

we did that and actually that had amazing side-effects

to viewer architecture 

yeah I can't spend the (00:21:22,9) on that

so performance

so Ruby's performance is often talked about as being sluggish

so let's kind of get an intuition for how good or bad that is

let me ask you question

if you had a hello world Sinatra route

right

and you were to pound it with requests

say using a patching bench or something

what kind of response sends can you expect

it's just a hello world

so just a get slash hello world

and just says hello world and returns

that's it right

some guesses of how long that would take

5 milliseconds

yeah

so, that's roughly, 

it takes about a millisecond

at the 95th percentile

but it takes nine to twelve milliseconds at the 99th percentile

and the max is around fourteen, right

if you run the same thing in JRuby

it will take about 2 milliseconds at the 95th percentile

and 99 would be about 5 milliseconds

and max also is actually about 5 milliseconds

so it's actually very very tightly bound

that's the beauty of JRuby right

because it's GC is so good

and the zip compilation is so good

that it's able to clearly optimize pieces of code

to give you very very stable response times

but there actually worse than MRI

so the bench marks that talk about JRuby being faster

I've never been able to reproduce those

so anyway that's the, an intuition about

so we actually end up getting much higher support

so, that same hello world server

will do about seven hundred requests per second

versus the JRuby one will take about five hundred fifty to five hundred and eighty

however

if you had a tomcat servlet doing hello world

how long do you think that would take

thirty?

yeah, it would be roughly in the 50 microseconds, it's about twenty times, twenty to forty times faster

so that is one of the big arguments that was made against you know using Ruby

why should you use Ruby it's so slow

but the point is this

it's still fine

perfectly fine

and that is because

most business applications are not CQ-boned, they're IO-boned

they're basically all just waiting for some horribly slow query to return

right

and it takes the same time waiting in Java or in Ruby

so that's why actually IO in managing, IO is the most important thing

that includes things like database calls

calls to external services

yeah

kind of optimizing that is the first priority of, for tuning Ruby apps

so given this we wanted to make sure that

all our services were kind of behaving welll

so we actually built a tool called drac metrics

which basically is a rack filter which will send the request cycle

and you can actually add plug-ins to monitor different parts of

the application so we had plug-ins for

Sinatra's routes so you can get into it and request time

we had plug-ins which can go to activerecord

and calculated the time for each query

and we, it hooked into desk client

and thrift clients

to basically instrument the time taken for all our outgoing calls

so the result was it would

oh look, you can't read it very well

essentially you'd see

you could go to any service

and ask for its metrics

I'll tell you all the routes that were defined

all the routes and how much total time was spent in them

the total count, we have average time and max, et cetera

and within each route, if you expanded it

it would tell you the

the five slowest requests for that route

so for example, for this inventory post, inventory call

there's the caller tells you how much DB time was spent

how many rest calls, how much rest calls

was split between different parts of the code

and it'll give you a list of all the external calls

and database queries made, right

so with this, you could immediately find out

that you're doing something stupid like

like an N plus 1 query, or the call to external system

to actually slow, and that kind of optimized 

you have a check list for kind of figuring out what

you want to attack first, right

so we'd use this, figure out the slow points

optimize that first

so, we also had an extensive monitoring through

StatsD and Graphite

so, Graphite allows you to kind of just push points to it

and it gives you a time series

you of the data, and we've got

again as Chad was saying

like metrics from business down to

tech metrics including CPU

and capacity and request response times

number of requests

so with this we also built a loading framework

which basically models Graphite

and you can define, OK, if this

threshold is breached for this metric

then send me a mailer SNS

so with these three pieces, we had the modeling in place

to kind of keep a check on our systems

right so, how do you tune that

once you kind of figure out the problems that

are typically there

it's actually fairly straighforward

if it's IO, fix the IO problem

if it's N plus 1 query, remove it

do an eager join, simple stuff

if it's a bad query, run MySQL Explain

or whatever query plan or tool you have for a database

you get the query plan, figure out what the optimal join struct-

join sequence, and actually fix the query

for external cause, we actually end up putting in very aggressive time-outs

so that, you don't have a thread or a process just waiting forever

for somebody else to respond, right

it, because that has very bad effects on capacity

of the entire cluster

because, for example, if you have a slow

if you have a service that is calling another service

and that service is running slow

you can end up completely freezing this calling service

because all the processes are just waiting for this guy to respond

right

so once these two are, these two kind of things are fixed

then it's important to look at GC itself

now, Ruby's default GC settings are actually very conservative

and you typically see initial just after restart

response kinds are kind of slow and they kind of get faster

they can work pretty fast but

there's still a lag, so

there are ways to kind of improve the default heap size

and the allocation rate and percentage and all that stuff

I've got a reference to that in the, at the end

but, I think that, that's something which we did

and that immediately improved our response times

so, this still doesn't address all problems, right

there are still cases where GC is still a problem

for example, there will be queries which just load a ton of data

say for example reporting queries

and those are tricky

so for those what we end up doing

is just carving out a separate cluster

this ear-mark tool, two loads in a cluster

for the recording queries

build a separate virtual IP, a separate rip

and point all those requests to those to those servers

even if that doesn't fix the problem with GC

then you've got to go down to profiling

so for profiling we end up using both tools

again a url link to it at the end

which is a great, great tool

it's, there are rack filters which can kind of mod the request

of, hook into the request cycle

and actually give you a grasp of the call-chains

along with how much time was being spent in each section

that's great

and that'll tell you how much time is spent in GC

or some section of code

so that's your final, final kind of hammer

you can kind of use to address performance issues

we also ended up clinging on quite a bit

with changing app source

so we moved from Trinidad in the JRuby world, time

to an MRI views, passenger first

and now we have been on Unicorn

and Unicorn particularly has a plug-in called the

Out-of-band GC which basically runs GC

on that, it basically disabled GC for that particular interpretator

and runs GC after the request cycle ends

right, so all your response, none of your requests actually see

bad response times due to GC

so that works beautifully actually

so really nice plug-in

there's also a plug-in called workerkiller

which can kind of get a look at the process of the memory threshold

so we use all these 

OK

so another problem that we faced, which was

we now have twenty-four, twenty-five services running

on Sinatra and Padrino apps

and there was a bunch of Ruby gems that we were using

which were the core platform gems which had to be shared

and each team worked independelty

so it ended up becoming a problem for the platform team

to kind of go and chanse around people

say OK create this gem, otherwise there's gonna be problems

and that was a big issue

so what we ended up doing was

creating a patch version of Bundler

which essentially allows you to annotate

each new Gem file, each Gem line with a auto-updated coded true flag

and then Bundlerbasically will

when you run Bundle install

it will basically check if there's a new version of that

same Gem in the repo, and actually

resolves dependencies and actually install that

so the nice thing with this was

it works in the Debs environment

it's not something that happens automatically in the background

you're weighing it, kind of messing around platform Gems

and it happens frequently enough that you know

everybody, the entire ecosystem kind of moves together

and upgrades the services quickly

ok, so - can I take five minutes? no?

all right, I'm... OK, I'll rush through, so OK

team-dynamics

so, we saw with the java team

and we kind of just threw them to the deep end into Ruby

and we just had to work three Ruby debs so

it took, on average I think, people about three to four months

to start writing idiomatic Ruby

and that was a big challenge so

we did a bunch of things to kind of address those problems

including kind of having consultants to

bear with the people on the time

having one expert per team et cetera

OK, I'll skip to... all right

so one of the things that we noticed, or

happened was that because Ruby's such a dynamic language

you can write such, such code so quickly

and so compactly 

sometimes it tends to, design tends to be taken for granted

I don't know if it's automatic or not

it will, it tends to be taken for granted

like people don't, just don't think, like OK there's a feature

then we decided quickly, it was not, yeah, let's not try to set it on them then

but I think this is a really big problem

because you end up, or rather you need to actually ask

very deep questions about the domain

and we actually got caught in this problem

a couple of times where we actually ended up creating

small custom solutions to specific problems 

instead of asking deep questions about it

what is this domain, what is this problem really about

what is warehousing, for example, really about

it's not about check lists and foot lists

it's about goods movement and material movement

and how do we model that as a first class concept right

and, I wonder if Ruby being a dynamic powerful language

actually cultivated that

that's more of, a question for me

OK, yeah, questions

the slides, the ones of references at the end

BACKGROUND: sorry you will get no questions

all right no questions

thank you guys

BACKGROUND: thanks for the insights Yogi
